{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic linear prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aruba/anaconda3/lib/python3.7/site-packages/statsmodels/compat/pandas.py:23: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_selection import RFE\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets ## import datasets from sklearn\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn import tree\n",
    "%matplotlib inline\n",
    "\n",
    "def classification_metrics(Y_pred, Y_true):\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    precision = precision_score(Y_true, Y_pred)\n",
    "    recall = recall_score(Y_true, Y_pred)\n",
    "    f1score = f1_score(Y_true, Y_pred)\n",
    "\n",
    "    return acc, precision, recall, f1score\n",
    "\n",
    "def display_metrics(classifierName,Y_pred,Y_true):\n",
    "    print (\"______________________________________________\")\n",
    "    print (\"Model: \"+classifierName)\n",
    "    acc, precision, recall, f1score = classification_metrics(Y_pred,Y_true)\n",
    "    print (\"Accuracy: \"+str(acc))\n",
    "    print (\"Precision: \"+str(precision))\n",
    "    print (\"Recall: \"+str(recall))\n",
    "    print (\"F1-score: \"+str(f1score))\n",
    "    print (\"______________________________________________\")\n",
    "    print (\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow.compat.v1 as tf\n",
    "# tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_data = pd.read_csv('shot_logs(original).csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         9\n",
       "3         1\n",
       "4         2\n",
       "         ..\n",
       "127946    5\n",
       "127947    2\n",
       "127948    0\n",
       "127949    2\n",
       "127950    0\n",
       "Name: DRIBBLES, Length: 127951, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shot_data.DRIBBLES.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         1\n",
       "3         0\n",
       "4         1\n",
       "         ..\n",
       "127946    0\n",
       "127947    0\n",
       "127948    0\n",
       "127949    1\n",
       "127950    0\n",
       "Name: FGM, Length: 127951, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shot_data2['FGM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shot_data2 = shot_data\n",
    "\n",
    "predictors1 = ['HOME']+['PERIOD']+['DRIBBLES']+['SHOT_DIS']+['TOUCH_TIME']+['SHOT_CLOCK']+ ['CLOSE_DEF_DIST']+[ 'Height_def']+['Age_def']+['DWS_def']+['BLK%_def']+['TRB%_def']+['STL%_def']+['USG%_def']+['TOV%_def']+['Height_off']+['Age_off']+['OWS_off']+['OBPM_off']+['FG%_off']+['USG%_off']+['TOV%_off']\n",
    "\n",
    "X = shot_data2[predictors1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = shot_data2['FGM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3,random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),    # take 2d to 1d sequence\n",
    "                                   tf.keras.layers.Dense(512,activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(128,activation = tf.nn.relu),  #If X>0 return X, else return 0\n",
    "                                  tf.keras.layers.Dense(10,activation = tf.nn.softmax)]) \n",
    "#[0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05] => [0,0,0,0,1,0,0,0,0] Take the highest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89565 samples\n",
      "Epoch 1/5\n",
      "89565/89565 [==============================] - 4s 40us/sample - loss: 0.6892 - accuracy: 0.5481\n",
      "Epoch 2/5\n",
      "89565/89565 [==============================] - 4s 40us/sample - loss: 0.6891 - accuracy: 0.5486\n",
      "Epoch 3/5\n",
      "89565/89565 [==============================] - 4s 40us/sample - loss: 0.6891 - accuracy: 0.5486\n",
      "Epoch 4/5\n",
      "89565/89565 [==============================] - 4s 40us/sample - loss: 0.6890 - accuracy: 0.5486\n",
      "Epoch 5/5\n",
      "89565/89565 [==============================] - 4s 40us/sample - loss: 0.6890 - accuracy: 0.5486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1337fadd8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(X_train,y_train,epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38386/38386 [==============================] - 1s 21us/sample - loss: 0.6904 - accuracy: 0.5462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6904120334321547, 0.5462408]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Homebrew...\n",
      "xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 3 taps (homebrew/cask-versions, homebrew/core and homebrew/cask).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "bic                                      iblinter\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Formulae\u001b[0m\n",
      "\u001b[1mapache-spark \u001b[32m✔\u001b[0m\u001b[0m             git-credential-manager     picard-tools\n",
      "\u001b[1moctave \u001b[32m✔\u001b[0m\u001b[0m                   gitbucket                  pig\n",
      "\u001b[1mreadline \u001b[32m✔\u001b[0m\u001b[0m                 grafana                    plantuml\n",
      "\u001b[1mscala \u001b[32m✔\u001b[0m\u001b[0m                    groovy                     pmd\n",
      "ansible                    groovysdk                  prestodb\n",
      "asciidoctorj               hadoop                     prestosql\n",
      "atlassian-cli              hcloud                     procyon-decompiler\n",
      "aws-cfn-tools              helm                       pulumi\n",
      "aws-okta                   helmfile                   rds-command-line-tools\n",
      "bagit                      hugo                       redpen\n",
      "basex                      igv                        renameutils\n",
      "beagle                     jadx                       sbt\n",
      "bfg                        jasmin                     sbuild\n",
      "bind                       javacc                     scala@2.12\n",
      "boot-clj                   jboss-forge                sdedit\n",
      "bundletool                 jdnssec-tools              siege\n",
      "byteman                    jenkins                    signal-cli\n",
      "carrot2                    jetty                      sjk\n",
      "cfr-decompiler             jetty-runner               skaffold\n",
      "circleci                   jflex                      skinny\n",
      "clojure                    jhipster                   smali\n",
      "clojurescript              joshua                     sn0int\n",
      "closure-compiler           jruby                      solr\n",
      "closure-stylesheets        jsonschema2pojo            solr@7.7\n",
      "cloud-watch                jsvc                       sonarqube\n",
      "cromwell                   kaitai-struct-compiler     sonarqube-lts\n",
      "crowdin                    kawa                       sqoop\n",
      "crystal-icr                kubectx                    stanford-corenlp\n",
      "csound                     kumo                       stanford-ner\n",
      "deno                       languagetool               stanford-parser\n",
      "dependency-check           lcm                        swagger2markup-cli\n",
      "derby                      liquidctl                  tailor\n",
      "detekt                     mahout                     tee-clc\n",
      "devspace                   mallet                     teleport\n",
      "dita-ot                    micronaut                  tika\n",
      "ditaa                      mill                       topgrade\n",
      "ec2-ami-tools              minikube                   traefik@1\n",
      "ec2-api-tools              minio                      typescript\n",
      "elb-tools                  minio-mc                   umlet\n",
      "exploitdb                  mmark                      upscaledb\n",
      "fastbit                    mockserver                 vault-cli\n",
      "fastlane                   monetdb                    vert.x\n",
      "fastqc                     mvnvm                      vnu\n",
      "flume                      nagios-plugins             walkmod\n",
      "flyway                     nifi                       weechat\n",
      "fmpp                       nomad                      wildfly-as\n",
      "fop                        opa                        wiremock-standalone\n",
      "frege                      openapi-generator          xmlsectool\n",
      "frege-repl                 openjdk@11                 yq\n",
      "galen                      orientdb\n",
      "gcviewer                   pgweb\n",
      "\n",
      "\u001b[31mError:\u001b[0m The following formula\n",
      "  gcc@7\n",
      "cannot be installed as binary package and must be built from source.\n",
      "Install the Command Line Tools:\n",
      "  xcode-select --install\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!brew install gcc@7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'cross_validation' from 'sklearn' (/usr/local/lib/python3.7/site-packages/sklearn/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e1f69eb77285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# import xgboost as xgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# from xgboost.sklearn import XGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m   \u001b[0;31m#Additional     scklearn functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_search\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'cross_validation' from 'sklearn' (/usr/local/lib/python3.7/site-packages/sklearn/__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import xgboost as xgb\n",
    "# from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional     scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images /255.0\n",
    "test_images = test_images /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2673 - accuracy: 0.9007\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2539 - accuracy: 0.9057\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2452 - accuracy: 0.9094s - loss: 0.2445 - ac\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.2369 - accuracy: 0.9107\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2302 - accuracy: 0.9139\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2216 - accuracy: 0.9164\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2175 - accuracy: 0.9189\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2101 - accuracy: 0.9218\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2038 - accuracy: 0.9238\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1988 - accuracy: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x171b7d470>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(training_images,training_labels,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 28us/sample - loss: 0.3577 - accuracy: 0.8822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35771688404679297, 0.8822]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0310018e-10 8.4261209e-11 2.1220249e-08 6.5299122e-13 1.3942476e-09\n",
      " 1.9787335e-04 1.4392743e-09 1.1902710e-02 1.7264316e-08 9.8789936e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "print(classifications[0])\n",
    "print(test_labels[0])\n",
    "# print(classifications[1])\n",
    "# print(test_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More neuron\n",
    "<li> more tme but higher accuracy <= given but the website but the actual is not '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.4747 - accuracy: 0.8305\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s 165us/sample - loss: 0.3574 - accuracy: 0.8689\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.3232 - accuracy: 0.8795\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s 171us/sample - loss: 0.2982 - accuracy: 0.8904\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.2796 - accuracy: 0.8972\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.3275 - accuracy: 0.8812\n",
      "[3.9511328e-06 1.6420168e-07 3.3093109e-08 2.9448112e-08 2.4541566e-06\n",
      " 4.8367925e-02 3.3755745e-07 7.8195117e-02 1.5826078e-06 8.7342840e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),  # change to 1024 neurons\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "model.compile(optimizer = tf.train.AdamOptimizer(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another layer \n",
    "There isn't a significant impact -- because this is relatively simple data. For far more complex data (including color images to be classified as flowers that you'll see in the next lesson), extra layers are often necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.4664 - accuracy: 0.8303\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.3555 - accuracy: 0.8699\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.3232 - accuracy: 0.8792\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2976 - accuracy: 0.8889\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.2812 - accuracy: 0.8953\n",
      "10000/10000 [==============================] - 0s 49us/sample - loss: 0.3370 - accuracy: 0.8758\n",
      "[1.1179625e-06 2.5203574e-06 6.3104488e-07 3.7198501e-07 9.5322656e-07\n",
      " 2.2186283e-02 1.0654470e-05 2.2329312e-02 5.2248029e-06 9.5546293e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(256, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# This version has the 'flatten' removed. Replace the above with this one to see the error.\n",
    "#model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different epoches\n",
    "Try 15 epochs -- you'll probably get a model with a much better loss than the one with 5 Try 30 epochs -- you might see the loss value stops decreasing, and sometimes increases. This is a side effect of something called 'overfitting' which you can learn about [somewhere] and it's something you need to keep an eye out for when training neural networks. There's no point in wasting your time training if you aren't improving your loss, right! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.4962 - accuracy: 0.8262\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.3741 - accuracy: 0.8651\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3364 - accuracy: 0.8764\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.3110 - accuracy: 0.8856\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2942 - accuracy: 0.8911\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2790 - accuracy: 0.8966\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2658 - accuracy: 0.9014\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2574 - accuracy: 0.9039\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2483 - accuracy: 0.9061\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2397 - accuracy: 0.9104\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2293 - accuracy: 0.9132\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2227 - accuracy: 0.9160\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2169 - accuracy: 0.9187\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2105 - accuracy: 0.9208\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2042 - accuracy: 0.9228\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1988 - accuracy: 0.9254\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1944 - accuracy: 0.9266\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1884 - accuracy: 0.9292\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1820 - accuracy: 0.9312\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1780 - accuracy: 0.9327\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1744 - accuracy: 0.9347\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1692 - accuracy: 0.9360\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1641 - accuracy: 0.9385\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.1613 - accuracy: 0.9387\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1567 - accuracy: 0.9409\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1528 - accuracy: 0.9430\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1505 - accuracy: 0.9434\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1461 - accuracy: 0.9453\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1435 - accuracy: 0.9460\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.1404 - accuracy: 0.9472\n",
      "10000/10000 [==============================] - 0s 26us/sample - loss: 0.3914 - accuracy: 0.8865\n",
      "[2.4101733e-21 4.6685085e-20 3.4943364e-21 7.6083790e-21 3.2003125e-22\n",
      " 1.2101344e-07 5.6626663e-18 2.0763841e-04 2.6409884e-19 9.9979228e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# This version has the 'flatten' removed. Replace the above with this one to see the error.\n",
    "#model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 2.9486 - accuracy: 0.6807\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 34us/sample - loss: 0.6819 - accuracy: 0.7474\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.6128 - accuracy: 0.7770\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.5737 - accuracy: 0.7991\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.5183 - accuracy: 0.8235\n",
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.5758 - accuracy: 0.8141\n",
      "[7.7931392e-17 5.3311986e-14 3.8876981e-31 3.3365081e-15 1.7587072e-21\n",
      " 1.6120808e-02 2.5916789e-19 9.4654866e-02 1.3427021e-16 8.8922435e-01]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# training_images = training_images/255.0\n",
    "# test_images = test_images/255.0\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "# This version has the 'flatten' removed. Replace the above with this one to see the error.\n",
    "#model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "print(classifications[0])\n",
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call BACK \n",
    "Stop when you reach a desirable level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "Train on 60000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.4971 - accuracy: 0.8258\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3757 - accuracy: 0.8652\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3386 - accuracy: 0.8775\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3150 - accuracy: 0.8846\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2968 - accuracy: 0.8901\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2806 - accuracy: 0.8966\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2706 - accuracy: 0.8989\n",
      "Epoch 8/30\n",
      "59168/60000 [============================>.] - ETA: 0s - loss: 0.2575 - accuracy: 0.9037已经差不多咯！有90%不错啦\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2580 - accuracy: 0.9033\n",
      "10000/10000 [==============================] - 0s 24us/sample - loss: 0.3636 - accuracy: 0.8693\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch,logs={}):\n",
    "        if (logs.get('accuracy')>0.9):\n",
    "            print('已经差不多咯！有90%不错啦')\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callbacks = myCallback()\n",
    "\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "training_images = training_images/255.0\n",
    "test_images = test_images/255.0\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=30, callbacks=[callbacks])\n",
    "\n",
    "model.evaluate(test_images, test_labels)\n",
    "\n",
    "classifications = model.predict(test_images)\n",
    "\n",
    "# print(classifications[0])\n",
    "# print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
